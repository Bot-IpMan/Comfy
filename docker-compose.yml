services:
  comfyui:
    image: ${COMFYUI_IMAGE:-comfyui:local}
    build:
      context: .
      dockerfile: Dockerfile
      args:
        TORCH_INDEX_URL: ${TORCH_INDEX_URL:-https://download.pytorch.org/whl/cu124}
    container_name: comfyui
    restart: unless-stopped

    ports:
      - "8188:8188"

    volumes:
      - ./comfyui/models:/opt/ComfyUI/models
      - ./comfyui/input:/opt/ComfyUI/input
      - ./comfyui/output:/opt/ComfyUI/output
      - ./comfyui/custom_nodes:/opt/ComfyUI/custom_nodes
      - ./comfyui/user:/opt/ComfyUI/user

    environment:
      NVIDIA_VISIBLE_DEVICES: all
      NVIDIA_DRIVER_CAPABILITIES: compute,utility
      PYTORCH_CUDA_ALLOC_CONF: "max_split_size_mb:64,garbage_collection_threshold:0.8"
      CLI_ARGS: "--listen --port 8188 --lowvram --preview-method auto --disable-smart-memory --force-fp16"

    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

    shm_size: 2gb
    ulimits:
      memlock: -1
      stack: 67108864
