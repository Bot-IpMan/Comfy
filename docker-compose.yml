services:
  comfyui:
    image: ${COMFYUI_IMAGE:-comfyui:local}
    build:
      context: .
      dockerfile: Dockerfile
      args:
        TORCH_INDEX_URL: ${TORCH_INDEX_URL:-https://download.pytorch.org/whl/cu124}
    container_name: comfyui
    restart: unless-stopped

    ports:
      - "8188:8188"

    volumes:
      - ./comfyui/models:/opt/ComfyUI/models
      - ./comfyui/input:/opt/ComfyUI/input
      - ./comfyui/output:/opt/ComfyUI/output
      - ./comfyui/custom_nodes:/opt/ComfyUI/custom_nodes
      - ./comfyui/user:/opt/ComfyUI/user

    environment:
      # NVIDIA
      NVIDIA_VISIBLE_DEVICES: all
      NVIDIA_DRIVER_CAPABILITIES: compute,utility
      
      # КРИТИЧНО: Шляхи до CUDA бібліотек
      LD_LIBRARY_PATH: "/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:${LD_LIBRARY_PATH}"
      
      # PyTorch
      PYTORCH_ALLOC_CONF: "max_split_size_mb:64,garbage_collection_threshold:0.8"
      
      # ComfyUI
      CLI_ARGS: "--listen --port 8188 --lowvram --preview-method auto --disable-smart-memory --force-fp16"

    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

    shm_size: 2gb
    ulimits:
      memlock: -1
      stack: 67108864

    healthcheck:
      test: ["CMD-SHELL", "python3 -c 'import urllib.request; urllib.request.urlopen(\"http://localhost:8188/\")'"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 90s
