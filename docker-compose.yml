services:
  comfyui:
    image: ${COMFYUI_IMAGE:-comfyui:local}
    build:
      context: .
      dockerfile: Dockerfile
      args:
        TORCH_INDEX_URL: ${TORCH_INDEX_URL:-https://download.pytorch.org/whl/cu121}
    container_name: comfyui
    restart: unless-stopped
    user: "1000:1000"
    privileged: true
    security_opt:
      - seccomp=unconfined
    cap_add:
      - IPC_LOCK
      - SYS_NICE
    
    dns:
      - 8.8.8.8
      - 1.1.1.1

    ports:
      - "8188:8188"

    volumes:
      - ./comfyui/models:/opt/ComfyUI/models
      - ./comfyui/input:/opt/ComfyUI/input
      - ./comfyui/output:/opt/ComfyUI/output
      - ./comfyui/custom_nodes:/opt/ComfyUI/custom_nodes
      - ./comfyui/user:/opt/ComfyUI/user

    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]

    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - CUDA_DEVICE_ORDER=PCI_BUS_ID
      - CUDA_VISIBLE_DEVICES=0
      - LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
      - PYTORCH_CUDA_ALLOC_CONF=backend:native,max_split_size_mb:128
      - ATEN_CPU_CAPABILITY=default
      - ATEN_DISABLE_CPU_CAPABILITY=avx,avx2,avx512,avx512_vnni,fma4
      - OMP_NUM_THREADS=1
      - MKL_NUM_THREADS=1
      - OPENBLAS_NUM_THREADS=1
      - NUMEXPR_NUM_THREADS=1
      - GLIBC_TUNABLES=glibc.cpu.hwcaps=-AVX2,-AVX,-FMA,-AVX512F
      - XFORMERS_DISABLED=1
      - MALLOC_ARENA_MAX=2
      - CLI_ARGS=--listen --port 8188 --lowvram --disable-smart-memory --disable-cuda-malloc --fp32-text-enc --preview-method none

    command: /usr/local/bin/docker-entrypoint.sh

    shm_size: 8gb
    ulimits:
      memlock: -1
      stack: 268435456
      nofile:
        soft: 65536
        hard: 65536

    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8188/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s
